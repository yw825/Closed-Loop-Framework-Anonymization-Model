{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcb0531-3f11-4d2c-9d56-6cc49e15d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel, wilcoxon, shapiro\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import gc\n",
    "import itertools\n",
    "from sklearn.utils import resample\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "from sklearn.base import clone\n",
    "import copy\n",
    "import gower\n",
    "\n",
    "import utils \n",
    "import model_train\n",
    "from constants import DATASET_CONFIGS\n",
    "import particle_swarm\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36bce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data currently used \n",
    "DATASET_NAME = \"YourDatasetNameHere\"  # Replace with your dataset name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the configuration dictionary for the Adult dataset\n",
    "config = DATASET_CONFIGS[DATASET_NAME]\n",
    "\n",
    "# Extract the file path of the dataset\n",
    "path = config[\"path\"]\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Perform data preprocessing (e.g., cleaning, encoding, normalization as defined in utils)\n",
    "df = utils.data_prep(df)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of ML models\n",
    "ML_models = [\n",
    "    (\"DT\", lambda: DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        random_state=42\n",
    "    )),\n",
    "\n",
    "    (\"NB\", lambda: GaussianNB()),\n",
    "\n",
    "    (\"RF\", lambda: RandomForestClassifier(\n",
    "        n_estimators=4,\n",
    "        max_depth=5,\n",
    "        max_features='sqrt',\n",
    "        criterion='entropy',\n",
    "        n_jobs=-1,\n",
    "        warm_start=False,   \n",
    "        random_state=42\n",
    "    )),\n",
    "\n",
    "    (\"LR\", lambda: LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "        max_iter=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "    \n",
    "    (\"SVM\", lambda: LinearSVC(\n",
    "        loss=\"hinge\",\n",
    "        random_state=42\n",
    "    )),\n",
    "\n",
    "    (\"LDA\", lambda: LinearDiscriminantAnalysis())\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525fca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary with all parameter values\n",
    "# =========================\n",
    "# PSO parameter settings\n",
    "# =========================\n",
    "PSO_PARAMETERS = {\n",
    "    # Core PSO\n",
    "    \"n_population\": 15,\n",
    "    \"maxIter\": 30,\n",
    "    'n_bootstrap': 10,\n",
    "\n",
    "    # Phase ratios\n",
    "    \"warmup_ratio\": 0.2,\n",
    "    \"adaptive_ratio\": 0.6,\n",
    "\n",
    "    # Particle reduction\n",
    "    \"keep_ratio\": 0.7,\n",
    "    \"elite_ratio\": 0.15,\n",
    "\n",
    "    # Phase 2 (adaptive)\n",
    "    \"patience_phase2\": 5,\n",
    "    \"epsilon_phase2\": 2e-3,\n",
    "    \"ratio_threshold\": 0.25,\n",
    "\n",
    "    # Phase 3 (exploitation)\n",
    "    \"patience_phase3\": 8,\n",
    "    \"epsilon_phase3\": 2e-5,\n",
    "\n",
    "    # Runtime control (seconds)\n",
    "    \"time_budget\": 240\n",
    "}\n",
    "    \n",
    "\n",
    "ANON_PARAMETERS = {\n",
    "    'gamma': 1,\n",
    "    'k': 20,\n",
    "    'initial_violation_threshold': 10,\n",
    "    'violation_decay_rate': 0.5,\n",
    "    'penalty_weight': 1,\n",
    "    'aggregate_function': 'mean'\n",
    "}\n",
    "\n",
    "BASE_PARAMETERS = {\n",
    "                **PSO_PARAMETERS,\n",
    "                **ANON_PARAMETERS\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a base path\n",
    "base_path = os.path.join(\n",
    "    \"Put your base path here\",  # Replace with your base path\n",
    "    DATASET_NAME,\n",
    "    \"Anonymized Data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87493671",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dataset_config = config  # clarity\n",
    "\n",
    "    for ML_name, ML_fn in ML_models:\n",
    "        print(f\"Training model: {ML_name}\")\n",
    "        print(\"-----\" * 10)\n",
    "\n",
    "        ML_model = ML_fn()\n",
    "\n",
    "        for n_cluster_val in dataset_config['n_cluster']:\n",
    "\n",
    "            print(f\"Running with k = {BASE_PARAMETERS['k']}, \"\n",
    "                  f\"n_cluster = {n_cluster_val}\")\n",
    "\n",
    "            # ✅ build params PER RUN\n",
    "            params = {\n",
    "                **BASE_PARAMETERS,\n",
    "                'n_cluster': n_cluster_val\n",
    "            }\n",
    "\n",
    "            with concurrent.futures.ProcessPoolExecutor(\n",
    "                max_workers=os.cpu_count()\n",
    "            ) as executor:\n",
    "\n",
    "                futures = [\n",
    "                    executor.submit(\n",
    "                        particle_swarm.run_single_experiment,\n",
    "                        i,                    # seed\n",
    "                        df,\n",
    "                        DATASET_NAME,\n",
    "                        ML_name,\n",
    "                        ML_model,\n",
    "                        params,               # ✅ packed\n",
    "                        dataset_config,       # ✅ packed\n",
    "                        base_path,\n",
    "                        experiment_runner=particle_swarm.run_particle_swarm_experiment_with_repairing # it can be changed to run_particle_swarm_experiment_without_repairing if you want to test the version without repairing or run_particle_swarm_experiment_QIs if you want to test the version with QIs only\n",
    "                    )\n",
    "                    for i in range(10)\n",
    "                ]\n",
    "\n",
    "                for future in concurrent.futures.as_completed(futures):\n",
    "                    future.result()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
